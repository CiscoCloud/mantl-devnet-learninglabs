# Networking for containers

Every container you create has an *eth0* interface with its own IP address:

![Networking ifconfig container](/posts/files/docker-201/assets/images/networking_ifconfig.png)

That *eth0* interface is connected to a peer *veth* in your host, that belongs to the default *docker0* virtual bridge between container and host.

![Networking ifconfig host](/posts/files/docker-201/assets/images/networking_ifconfig2.png)

*ip tables* make sure that traffic only flows between containers in the same virtual bridge.

Check the existing networks by default in a host with `docker network ls`.

![Docker network ls](/posts/files/docker-201/assets/images/docker_network_ls.png)

* 'bridge' is the default one, and it maps to *docker0* virtual bridge (the one you see when running `ifconfig` in the host)
* 'host' maps the container directly to the host, so it is not recommended due to security concerns
* 'none' provides no connectivity at all

Before we start discussing networking options for containers, let's dig a little bit more into how containers connectivity works.

You will now create an image in your local host that responds to *http* requests with its own IP address:

1.- Create the following directory structure: ./www/cgi-bin/

```
mkdir ./www
mkdir ./www/cgi-bin
```

2.- Create a file (`vi ./www/cgi-bin/ip`) with the following script to find out the container IP address:

```
#! /bin/sh
echo
echo "Container IP: $(ifconfig eth0 | awk '/inet addr/{print substr($2,6)}')"
```

3.- Create a Dockerfile for an image based on *alpine*, that copies the content of *./www* from the local host to */www* in the container, then installs *bash* & *curl* and gives required execution permissions to the content of */www/cgi-bin*, publishes port 8000, and defines the default command as an *http* server on port 8000 for the script stored in */www*.

```
FROM alpine:3.3
ADD www /www
RUN apk add --no-cache bash curl && chmod -R 700 /www/cgi-bin
EXPOSE 8000
CMD ["/bin/busybox", "httpd", "-f", "-h", "/www", "-p", "8000"]
```

4.- You can then build the image with `docker build -t $your_docker_id/$your_app_name .`

![Networking docker build](/posts/files/docker-201/assets/images/networking_docker_build.png)

5.- Now run a detached container based on that image, serving on port 8000 **but not mapped to any port in the host**:

```
docker run -d --name myapp $your_docker_id/$your_app_name
```

![Networking docker run](/posts/files/docker-201/assets/images/networking_docker_run.png)

6.- Connect to the container, check interface *eth0* (the one connected to *docker0* virtual bridge), and verify it has the same IP address obtained via *http* with the `curl` command.

```
docker exec -it myapp /bin/bash
    ifconfig
    curl localhost:8000/cgi-bin/ip
    exit
docker rm -f myapp
```

![Networking first curl](/posts/files/docker-201/assets/images/networking_curl1.png)

7.- Now let's make the container *http* service available from the host as well. To accomplish this we need to map the container exposed port (8000) to a defined host port (in this case also port 8000, though we might have used a different one).

```
docker run -d -p 8000:8000 --name myapp $your_docker_id/$your_app_name
curl localhost:8000/cgi-bin/ip
```

![Networking second curl](/posts/files/docker-201/assets/images/networking_curl2.png)

8.- Check the exposed port for the image and container:

```
docker inspect --format "{{ .ContainerConfig.ExposedPorts }}" $your_docker_id/$your_app_name
docker port myapp
```

![Networking port mapping](/posts/files/docker-201/assets/images/networking_port_mapping.png)

9.- Finally assign the port in the host to a variable in your local host, and use that variable to run the request again:

```
PORT=$(docker port myapp | cut -d ":" -f 2)
curl "localhost:$PORT/cgi-bin/ip"
```

![Networking third curl](/posts/files/docker-201/assets/images/networking_curl3.png)

#### Congratulations! You have successfully built your app and containerised it. Let's now use it for our networking tests.

## Option 1: Networking containers with variables

Run one container (C1) in detached mode with the image you just created, and store the IP address assigned to it in a **host** variable:

```
docker run -d --name myapp $your_docker_id/$your_app_name
TESTING_IP=$(docker inspect --format "{{ .NetworkSettings.IPAddress }}" myapp)
echo $TESTING_IP
```

![Networking1 run](/posts/files/docker-201/assets/images/networking1_run.png)

You may also inspect the default virtual bridge network to see the IP address assigned to your container: `docker network inspect bridge`

Now run an additional container (C2), based on the same image you created, but this time make it interactive (with `-it` parameter). Most importantly pass it an environment variable (with `-e` parameter) with the IP address of the first container (C1), so that you can use it to ping from C2 to C1.

```
docker run --rm -it -e TESTING_IP=$TESTING_IP $your_docker_id/$your_app_name /bin/bash
    ping $TESTING_IP -c 2
```

![Networking1 ping](/posts/files/docker-201/assets/images/networking1_ping.png)

This is the most basic way of linking containers. It is static, so in case a container restarts it will probably change its IP address and will need to assign again the correct IP to the defined variable.


## Option 2: Networking containers with *links*

Please verify you still have the first container (C1) from the previous section with `docker ps -a`.

Now let's run a second container (C2') in interactive mode (with `-it`), but this time creating a link/alias to the first container (C1), so that you can ping from C2' to C1. You create the alias with the `--link` parameter, and specify the name of the container you want to link to and the *alias* you want to use from your container (C2').

```
docker run --rm -it --link myapp:container1 $your_docker_id/$your_app_name /bin/bash
    ping container1 -c 2
```

![Networking2 ping](/posts/files/docker-201/assets/images/networking2_ping.png)

This is also static, so in case one container restarts it will need all the linked containers to restart as well, so that port numbers are updated in their */etc/hosts* files. The reason is that the `--link` parameter updates the */etc/hosts* in C2' with an entry for C1, but if C1 restarts then the */etc/hosts* file in C2' is not automatically updated, so it will keep on trying to use the old IP address for C1.

## Option 3: Networking containers with user networks

This time we will use user-defined bridges, which automatically discover containers, and provide a DNS service (with no *etc/hosts* at all).

First let's create a new docker network, with `docker network create mynet`.

Then we run 2 containers in detached mode, connected to that network and specified with the `--net` parameter:

```
docker run -d --net=mynet --name myapp1 $your_docker_id/$your_app_name
docker run -d --net=mynet --name myapp2 $your_docker_id/$your_app_name
```
![Networking3 run](/posts/files/docker-201/assets/images/networking3_run.png)

You may now inspect the newly created docker network and see the IP addresses assigned to your containers, with `docker network inspect mynet`.

Now you can try connectivity between your containers by connecting to the first one and try ping to the second one using its name:

```
docker exec -it myapp1 /bin/bash
    ping myapp2 -c 2
```

![Networking3 ping](/posts/files/docker-201/assets/images/networking3_ping.png)

You can manually disconnect one of the containers from the network, and inspect it again to see its IP does not show anymore:

```
docker network disconnect mynet myapp2
docker network inspect mynet
```

Finally you can delete your network with `docker network rm mynet`, but first you need to stop and delete at least the container still connected to *mynet*, with `docker rm -f myapp1`.

# Storage for containers

By now you may already be wondering "if containers come and go so frequently and they are auto-contained, what happens with the information I want to preserve?". Well, you are in the right place. Let's explore what options we have to make sure information that needs to persist is not lost when containers are destroyed.

## Step 1: Sharing storage between host and container

The first thing that will come handy is learning how to mount a host local folder inside a container. Let's create a file (*testfile*) inside a *temp* folder in our host, and then run an interactive container that maps that host folder (*temp*) into a container **volume**. This is accomplished with the `-v` parameter, where we define the local host folder path and the target volume in the container.

```
mkdir ~/temp
cd ~/temp
echo "Hello" > testfile
docker run --rm -it -v ~/temp:/data ubuntu /bin/bash
```

![Storage 1](/posts/files/docker-201/assets/images/storage1.png)

Once inside the container please check you can see the content of the file from the host, and modify it by appending some info.

```
cat /data/testfile
cd /data/
echo “appended from $(hostname)” >> testfile
exit
```

![Storage 2](/posts/files/docker-201/assets/images/storage2.png)

Now that you are back in your host please verify the update appended from the container is also visible from the host.

```
cat ~/temp/testfile
```

![Storage 3](/posts/files/docker-201/assets/images/storage3.png)

## Step 2: Sharing storage between containers

Next thing you need to learn is how to share Docker volumes among containers, as this is frequently used to share information between running containers.

First run a detached container and create a new volume (*/data*) with the `-v` parameter:

```
docker run -itd --name myapp -v /data ubuntu
```

Let's connect to this container and update a file in that volume with the hostname of the container:

```
docker exec -it myapp /bin/bash
    cd /data
    echo "appended from $(hostname)" >> volfile
    exit
```

![Storage 4](/posts/files/docker-201/assets/images/storage4.png)

Now you create another container that maps the already created volume from the first container (with the `--volumes-from` parameter), and check that the hostname appended is the one from the first container:

```
docker run --rm -it --volumes-from myapp ubuntu /bin/bash
    cat /data/volfile
    hostname
```

![Storage 5](/posts/files/docker-201/assets/images/storage5.png)

One important remark is that the volumes names are randomly assigned, please check it with `docker volume ls`.

![Storage 6](/posts/files/docker-201/assets/images/storage6.png)

So it is better to specify a meaningful name when creating volumes:

```
docker run --rm -it -v myvol:/data ubuntu /bin/bash
  exit
docker volume ls
```

![Storage 7](/posts/files/docker-201/assets/images/storage7.png)


#### Congratulations! You have learned some different ways to provide connectivity and storage to containers, and what are the specific concerns for some of them. Read on to learn how to manage a number of containers belonging to a single service!
