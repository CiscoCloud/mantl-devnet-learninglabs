# Docker Compose

Usually applications are composed by a number of containers that interact among them to provide the defined service. Docker Compose is a useful tool to orchestrate these containers that belong to the same service, so that we do not need to manage them individually, but rather as a joint entity. The format of the file used by this tool is [YAML](https://en.wikipedia.org/wiki/YAML).

If you plan to use your own environment please make sure to [install Docker Compose](https://docs.docker.com/compose/install/) before starting this part of the lab. The [play-with-docker](http://play-with-docker.com) environment already includes it, so no additional installation is required.

The easiest way to learn about Docker Compose is to work on some simple examples like the following ones.

### Example 1 - Connectivity

First you need to create the required YAML file in your local directory, with `vi docker-compose.yml` (please note you need to use that specific file name for this tool), and add the following content (indentation for each line is critical).

```
myapp:
  image: <your docker id>/<your app name>
someclient:
  image: <your docker id>/<your app name>
  container_name: someclient
  command: sleep 500
  links:
  - myapp
```

Note: as with the previous labs you need to replace your_docker_id/your_app_name with your own info.

This example YAML file defines 2 containers to run: 'myapp' and 'someclient', both based on the same image we created. For the second container it defines a specific 'container-name' (like we did in previous steps with the `--name` parameter), a customised command to run when the container is created instead of the default one defined for the image, and a link to the first container (*myapp*).

Now you can use Docker Compose to run those containers defined in the YAML file, in detached mode (`-d`):

```
docker-compose up -d
```

As you can see with `docker ps -a` the container for 'myapp' has been assigned a pseudo-random name (no specific *container_name* was assigned in the docker-compose.yml file), and 'someclient' is executing a different command than the default one for the image.

![Compose 1](/posts/files/docker-201/assets/images/compose1.png)

Connect now to the 'someclient' container and ping 'myapp' by its name, as defined in the YAML file:

```
docker exec -it someclient /bin/bash
    ping myapp -c 2
```

![Compose 2](/posts/files/docker-201/assets/images/compose2.png)

As you can see there is connectivity between the 2 containers because of the 'links' definition.

You can now bring down all the containers in this service with `docker-compose kill`, and then remove them with `docker-compose rm -f`.

### Example 2 - Load Balance

For this one we will use a new image called *haproxy*, which is a load-balancer serving in port 80 that will redirect traffic all containers defined in *myapp*.

Create the required YAML file in your local directory, with `vi docker-compose.yml` and the following content:

```
myapp:
  image: <your docker id>/<your app name>
haproxy:
  image: dockercloud/haproxy
  container_name: haproxy
  links:
    - myapp
  ports:
    - 80:80
```

Bring it up with `docker-compose up -d`.

![Compose 3](/posts/files/docker-201/assets/images/compose3.png)

This started one *haproxy* container linked to one *myapp* container. As per the file definition *haproxy* offers its service in port 80, and it is mapped to port 80 in the host. Please note that this `80:80` does not relate at all to port 8000 where *your_app_name* provides its service. You may check used ports with `docker-compose ps`.

![Compose ps](/posts/files/docker-201/assets/images/compose_ps.png)

If you `curl` your host in the default port 80, this will get forwarded to port 80 of *haproxy*, and then the request will be load-balanced to containers in *myapp*, providing its IP address.

![Compose curl 1](/posts/files/docker-201/assets/images/compose_curl1.png)

As long as the *haproxy* load-balancer is currently only balancing traffic to 1 container in *myapp*, let's scale *myapp* to have 2 containers in it, with the `--scale` parameter.

```
docker-compose down
docker-compose up --scale myapp=2 -d
```

![Compose scale up](/posts/files/docker-201/assets/images/compose_scale_up.png)

As you can see now there are 2 containers for *myapp*, and *haproxy* will load-balance requests to them. You may test this with `curl localhost/cgi-bin/ip`.

![Compose balanced](/posts/files/docker-201/assets/images/compose_balanced.png)

You can now bring down all the containers in this service with `docker-compose kill`, and then remove them with `docker-compose rm -f`.

### Example 3 - WordPress

WordPress, the world-famous blogging solution, includes a front-end application and a back-end database. We can build this architecture using containers, and orchestrate its creation and connectivity with *docker-compose*.

Let's create the required YAML file in your local directory, with `vi docker-compose.yml` and the following content:

```
wordpress:
  image: wordpress
  links:
    - db:mysql
  ports:
    - 8080:80

db:
  image: mariadb
  environment:
    MYSQL_ROOT_PASSWORD: Nbv12345!
```

The YAML file defines 2 services: *wordpress* and *db*. The first one (*wordpress*) uses a verified Docker image 'wordpress', links it to the *db* service specifying it is a *mysql* database, and maps its service port 80 to port 8080 in your local host. The second service (*db*) specifies another verified Docker image 'mariadb', and provides the required password as an environment variable.

As usual bring them up with `docker-compose up -d`.

![Compose wordpress](/posts/files/docker-201/assets/images/compose_wp.png)

If you were running this in your own environment now you would be able to point your browser to `localhost:8080` and enjoy a fresh WordPress installation:

![WordPress install](/posts/files/docker-201/assets/images/wordpress_install.png)

However the *play-with-docker* environment does not offer you this option, but we can test that everything still works by using `curl localhost:8080/wp-admin/install.php`, which is the URL you get redirected to in your browser:

![WordPress install curl](/posts/files/docker-201/assets/images/wordpress_install_curl.png)

You can now bring down both containers in this service with `docker-compose kill`, and then remove them with `docker-compose rm -f`.

#### Congratulations! You have now learned how to manage several containers that belong to a single service. Again, in a real-life deployment you will use an orchestration solution (like Swarm or Kubernetes) that will help with the management of service containers.

#### Please read on to understand how Swarm native orchestration works for Docker containers!
