# Who made hello-world?

How did the author of the "hello-world" image make it? Because it's
available on the public DockerHub repository, we can inspect the image
and find out.

Browse to [the "hello world" web
page](https://hub.docker.com/_/hello-world/) to see details describing
the Docker image.

![docker hub website](/posts/files/docker-101/assets/images/dockerhub1.png)

 One of those details is a link to the __Dockerfile__, the file that
defines the image.

![Dockerfile](/posts/files/docker-101/assets/images/dockerfile1.png)

# The Dockerfile

Every Docker image, from a simple one like "hello-world" to a full,
complex application, is defined by a __Dockerfile__. The Dockerfile is
a text file that describes programs and resources that become part of
the Docker image. Most image authors store their Dockerfiles together
with related application code in a revision-control repository.

With a Dockerfile and the related application code available, the
author of an image can use Docker to build and share the
image. Executing the `docker build` command collects the programs and
resources identified by the Dockerfile and uses them to construct a
Docker image in the current directory. Once the Docker image is built,
the author pushes it to the public repository on DockerHub, making it
available to everyone.

![hello-world codebase](/posts/files/docker-101/assets/images/hello-codebase.png)

# The "hello-world" Dockerfile

This is the hello-world Dockerfile:

```
FROM scratch
COPY hello /
CMD ["/hello"]
```

Simple right? Here's what it tells `docker build .` to do:

    FROM scratch

    * We can build on existing docker images if we wish. ’scratch’
      means start with a completely empty container.

    COPY hello /

    * Copy the local file ‘hello’ into the container image. (This is
      why we keep Dockerfiles in our application source directory, so
      we can refer to the pieces of our app we want pulled into the
      container.)

    CMD ["/hello"]

    * The command to run inside the image whenever someone `docker
      run`'s your image.

# App dependancies

Putting your apps in a container isolates them, so the app still needs
all it's dependancies IN the container image.

in the hello-world example, the compiled binary ‘hello’ was the only
thing in the container, it works because it needed no
dependencies. Putting it in a container isolated it from the rest of
the system and made it easily shareable with other developers who can
simply run `docker run hello-world`.

But what if we wanted to run something more complex like NGINX (a
webserver) as part of our containerized application? There will be a
lot more dependancies, system libraries needed etc.

ldd shows us linked libraries (dependancies) needed by a C
application; we can see NGINX has dependancies:

![NGINX dependancies](/posts/files/docker-101/assets/images/ldd1.png)

In the Sever / VM model, these dependencies would be installed as
extra packages via your package management tool (APT, YUM, etc)
however we have a blank container, theres no apt, yum tools..

## Full OS userspace containers

A container can have a whole Linux userspace within it to build on
(such as Ubuntu) in order to make complex software installs easier
within containers.

The downside being the container image will end up being a lot bigger
(100's of MB), however it means your Dockerfile can contain `apt-get
instal` commands (because those tools are already IN the container).

```
docker search ubuntu
```

We see an existing ubuntu container image on the public hub.

Run the container now.

```
docker run -ti ubuntu
```

This run's an ubuntu container for us, notice it drops us into the
ubuntu BASH shell within the container.

![Ubuntu shell](/posts/files/docker-101/assets/images/ubuntu1.png)

(This is what `-ti` is for, it tells docker we want to interact on the
terminal with the container.)

# Testing Isolation.

In our container, if we create a file in root (/), notice that when we
exit the container, the file doesnt exist on the VM outside the
container.

The container has no idea theres anything outside of it.

```
touch /hello
ls /

#exit the container
exit

#run an LS on the VM
ls /
```

Notice the hello file was not there on the last `ls`, it was only
within the container.

Also, in this instance, typing `exit` in the container has killed the
container. We can see which containers are running on our system with
`docker ps`

Notice there are no containers running.

If we run `docker run -ti ubuntu` again, this will be a BRAND NEW
instance of the ubuntu container, the `/hello` file won't be there, as
it wasnt baked into the ubuntu docker image.

### Changes to a running docker container dont survive once the
    container is killed.

If you want something in every instance of your docker container, you
bake it in by updating the Dockerfile and rebuilding your container
image.

# The ubuntu Dockerfile

Lets look at the Dockerfile which built the ubuntu image we just
ran...

You can find it once again at [https://hub.docker.com/_/ubuntu/]()

Click though to the Dockerfile just like we did with hello-world.

Notice theres a lot more in the DockerFile, but the concepts are
exactly the same:

```
FROM scratch
ADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz /

CMD ["/bin/bash"]
```

The dockerfile gets a whole ubuntu userspace (all the tools, binaries,
libraries) from a compressed .tar file and extracts it to the root of
the image.

Why did the ubuntu container give us a BASH shell when we ran it?
Because thats the CMD specified in the Dockerfile!

Again the Dockerfile is in the same source code repository as the
needed files (such as the .tar.gz archive)

![Ubuntu Repo for Docker
 Build](/posts/files/docker-101/assets/images/ubunturepo1.png)

I think we know enough now to build our OWN docker container with a
dockerfile... Click next to get going!
