# Who made hello-world?

How did the author of the "hello-world" image make it? Because it's
available on the public DockerHub repository, we can inspect the image
and find out.

Browse to [the "hello world" web
page](https://hub.docker.com/_/hello-world/) to see details describing
the Docker image.

![docker hub website](assets/images/dockerhub1.png)

 One of those details is a link to the __Dockerfile__, the file that
defines the image.

![Dockerfile](assets/images/dockerfile1.png)

# The Dockerfile

Every Docker image, from a simple one like "hello-world" to a full,
complex application, is defined by a __Dockerfile__. The Dockerfile is
a text file that describes programs and resources that become part of
the Docker image. Most image authors store their Dockerfiles together
with related application code in a revision-control repository.

With a Dockerfile and the related application code available, the
author of an image can use Docker to build and share the
image. Executing the `docker build` command collects the programs and
resources identified by the Dockerfile and uses them to construct a
Docker image in the current directory. Once the Docker image is built,
the author pushes it to the public repository on DockerHub, making it
available to everyone.

![hello-world codebase](assets/images/hello-codebase.png)

# The "hello-world" Dockerfile

This is the hello-world Dockerfile:

```
FROM scratch
COPY hello /
CMD ["/hello"]
```

Simple right? Here's what it tells `docker build .` to do:

    FROM scratch

    * "FROM scratch" means that the new Docker image starts with a
      fresh, empty container. It's also possible to build an image
      based on one that already exists. To do that, change "scratch"
      to the name of the starting container.

    COPY hello /

    * Copy the local file ‘hello’ into the root of the container
      image. The reason for storing Dockerfiles together with related
      application files is so that the Dockerfile can conveniently
      refer to those files and direct Docker to add them to a
      container.

    CMD ["/hello"]

    * Run the command "hello" when the container image starts. When
      someone uses `docker run` to execute this container image, the
      `CMD` script runs.

# Application Dependencies

When an application runs from a Docker container, it's completely
isolated from the system it's running on. That means that every
program and other resource that you application needs to run must be
included in the container image. The author of a container image has
to ensure that everything the application needs is included in the
image or it won't work correctly.

In the "hello-world" example the only resource that the image needs is
the compiled binary `hello`. The Dockerfile mentions no other
resources because none are needed for it to run.

What if a Docker image runs something more complicated, like the NGINX
web server? NGINX requires a long list of suporting files and
libraries in order to work. A Dockerfile that builds an NGINX image
must take care to include all of those dependencies in the container
or it'll fail to work.

To determine the linked libraries needed by a compiled C program, use
the command `ldd`:

![NGINX dependancies](assets/images/ldd1.png)

If we were building a server to run NGINX, or if we were preparing a
virtual machine, we would use operating-system package managers to
install all of the libraries and other resources that NGINX needs, but
that's not what we're doing. Building a Docker container to run a
complex application like NGINX requires a different approach.

## Full OS-Userspace Containers

A container image can be built with a complete Linux userspace inside
it. You can, for example, build a Docker container image that contains
all of the parts of the Ubuntu system needed to run NGINX.

On the one hand, building a whole userspace into a container means
that the container image may be quite large&mdash;perhaps hundreds of
megabytes.

On the other hand, it means that even a complex application with many
dependencies can be delivered in the form of a container image. The
container can even include operating-system package-management
software like apt or yum for use in configuring optional dependencies.

Suppose you want to build a container image that includes the whole
ubuntu system. Begin by searching DockerHub for a suitable container
to start with:

```
docker search ubuntu
```

We're in luck; DockerHub has an existing Ubuntu container.

Run the container now.

```
docker run -ti ubuntu
```

The example command runs the Ubuntu container from DockerHub. The
commad-line flags "-ti" tell Docker that we want to interact with a
shell in the running image. As soon as the image finishes launching it
dutifully drops us into the shell.

![Ubuntu shell](assets/images/ubuntu1.png)

# Testing Isolation.

In our container, if we create a file in root (/), notice that when we
exit the container, the file doesnt exist on the VM outside the
container.

The container has no idea theres anything outside of it.

```
touch /hello
ls /

#exit the container
exit

#run an LS on the VM
ls /
```

Notice the hello file was not there on the last `ls`, it was only
within the container.

Also, in this instance, typing `exit` in the container has killed the
container. We can see which containers are running on our system with
`docker ps`

Notice there are no containers running.

If we run `docker run -ti ubuntu` again, this will be a BRAND NEW
instance of the ubuntu container, the `/hello` file won't be there, as
it wasnt baked into the ubuntu docker image.

### Changes to a running docker container dont survive once the
    container is killed.

If you want something in every instance of your docker container, you
bake it in by updating the Dockerfile and rebuilding your container
image.

# The ubuntu Dockerfile

Lets look at the Dockerfile which built the ubuntu image we just
ran...

You can find it once again at [https://hub.docker.com/_/ubuntu/]()

Click though to the Dockerfile just like we did with hello-world.

Notice theres a lot more in the DockerFile, but the concepts are
exactly the same:

```
FROM scratch
ADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz /

CMD ["/bin/bash"]
```

The dockerfile gets a whole ubuntu userspace (all the tools, binaries,
libraries) from a compressed .tar file and extracts it to the root of
the image.

Why did the ubuntu container give us a BASH shell when we ran it?
Because thats the CMD specified in the Dockerfile!

Again the Dockerfile is in the same source code repository as the
needed files (such as the .tar.gz archive)

![Ubuntu Repo for Docker
 Build](assets/images/ubunturepo1.png)

I think we know enough now to build our OWN docker container with a
dockerfile... Click next to get going!
